{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TD1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW089G3VBr1R",
        "colab_type": "text"
      },
      "source": [
        "L'objectif principal de ce premier TD est de se familiariser avec Google Colab. \n",
        "\n",
        "Nous regarderons également le dataset avec lesquelles nous travaillerons sur les prochains cours. \n",
        "\n",
        "Colab est un Notebook gratuit qui fonctionne entièrement dans le cloud. Il vous permet de modifier des documents, comme vous le faites avec Google Docs. Colab prend en charge de nombreuses bibliothèques de Machine Learning populaires qui peuvent être facilement chargées dans votre Notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8CGsgyIDE8X",
        "colab_type": "text"
      },
      "source": [
        "# Interface Notebook\n",
        "\n",
        "Pour ceux qui n'ont jamais utilisé un Notebook comme Jupyter, nous allons explorer quelques outils pratiques.\n",
        "\n",
        "Une **cellule** est un conteneur pour le texte à afficher dans le notebook ou le code à exécuter par le noyau du notebook.\n",
        "\n",
        "Il y a deux principaux types de cellule que nous allons couvrir :\n",
        "\n",
        "* Une cellule de Code contient du code à exécuter dans le noyau. Lorsque le code est exécuté, le notebook affiche la sortie sous la cellule de code qui l'a généré.\n",
        "* Une cellule Texte contient du texte formaté à l'aide de Markdown et affiche sa sortie en place lorsque la cellule Texte est exécutée.\n",
        "\n",
        "Faisons un essai avec un exemple classique de \"hello world\" :\n",
        "\n",
        "Tapez `print('Hello World!')` dans la cellule Code suivante et cliquez sur le bouton d'exécution situé dans la partie gauche de la cellule ou appuyez sur Ctrl + Entrée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmuZ0x_oFClr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Hello World!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxpurXL3FVwU",
        "colab_type": "text"
      },
      "source": [
        "Lorsque nous lançons la cellule, sa sortie est affichée ci-dessous et le libellé à sa gauche aura changé de `In [ ]` à `In [1]`.\n",
        "\n",
        "Le nombre entre crochets indique l'ordre dans lequel la cellule a été exécutée ; la première cellule a un 1 parce que c'est la première cellule que nous avons exécutée. Nous pouvons exécuter chaque cellule individuellement à tout moment et ces chiffres changeront.\n",
        "\n",
        "Vous pouvez toujours faire la différence entre les cellules Code et Texte car les cellules Code ont cette étiquette à gauche et les cellules Texte non."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81HNhPCCFu9O",
        "colab_type": "text"
      },
      "source": [
        "# Mise en place de votre Drive\n",
        "\n",
        "**Créez un dossier pour votre projet.**\n",
        "\n",
        "Techniquement parlant, cette étape n'est pas totalement nécessaire si vous voulez simplement commencer à travailler à Colab. Cependant, puisque Colab fonctionne à partir de votre Drive, ce n'est pas une mauvaise idée de spécifier le dossier dans lequel vous voulez travailler. Vous pouvez le faire en allant sur votre Google Drive et en cliquant sur \"Nouveau\", puis en créant un nouveau dossier appelé *IA_MIAGE*.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/450/1*Rp17M-6CBfynldko2V4jmg.png\" width=200/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfBpkl69G4sg",
        "colab_type": "text"
      },
      "source": [
        "Toutes les lignes de code de ce TD supposeront que vous pouvez lire et écrire les fichiers du dossier *IA_MIAGE* situé dans votre compte Drive. C'est pourquoi il est important que vous accordiez l'accès à vos fichiers Drive à partir de ce Notebook. Cela permettra également de stocker toutes les modifications dans votre compte Drive. \n",
        "\n",
        "Pour monter votre Drive, procédez comme suit :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtLB2CN0BpkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNTu9SAIIs4F",
        "colab_type": "text"
      },
      "source": [
        "Lancez la cellule, cliquez sur le lien, copiez le code de la page, collez-le dans la case, appuyez sur Entrée, et vous verrez ceci lorsque vous aurez monté votre Drive avec succès\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/875/1*VrRLOThfoTpy_2ruTzV3yg.png\" width=500/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM-EaSJTJC0H",
        "colab_type": "text"
      },
      "source": [
        "Vous pouvez également voir la hiérarchie des fichiers en cliquant sur l'icône *dossier* en haut à gauche sous les boutons de contrôle (CODE, TEXTE). (Vous devrez peut-être appuyer sur \"refresh\".) De plus, vous pouvez accéder à votre Drive à tout moment avec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ3T5KCHJHdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaQ4dViiJKto",
        "colab_type": "text"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "Le [dataset](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html) que nous utiliserons est le  . Il contient 65 000 énoncés d'une seconde de 30 mots courts, prononcés par des milliers de personnes différentes.\n",
        "\n",
        "Suivez les instructions suivantes pour télécharger les données:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Pq0C4fJYLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% cd /content/drive/'My Drive'/IA_MIAGE/\n",
        "! git clone https://gitlab.com/baptiste.pouthier/google-speech-dataset.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q-RKXbhOHgq",
        "colab_type": "text"
      },
      "source": [
        "Dans le dossier *IA_MIAGE*, vous trouverez un dossier *google-speech-dataset*. Dans ce dossier, il y a un dossier par mot contenant des fichiers audio de différentes personnes mentionnant le mot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06-g-MD9Ofet",
        "colab_type": "text"
      },
      "source": [
        "Ignorons certaines classes qui ne sont pas utiles pour notre projet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEeGYoHJLTz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "dataset_path = \"/content/drive/My Drive/IA_MIAGE/google-speech-dataset/\"\n",
        "all_classes = os.listdir(dataset_path)\n",
        "all_classes.remove('.git')\n",
        "all_classes.remove('bird') #some outliers in dataset\n",
        "all_classes.remove('_lab_ressources_')\n",
        "all_classes.remove('_background_noise_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt0AeBZOO1EY",
        "colab_type": "text"
      },
      "source": [
        "Regardons toutes les mots disponibles dans le dataset. Chaque mot constituera une classe dans notre dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEXpLlKzO-sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('toutes les classes disponibles:\\n',all_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgQvqu5YPwAi",
        "colab_type": "text"
      },
      "source": [
        "Découvrons les audios d'une des classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UpcbyVKP66n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Audio\n",
        "import glob\n",
        "\n",
        "class_to_explore = \"dog\"\n",
        "audios_path = glob.glob(dataset_path + class_to_explore + \"/*\")\n",
        "idx_audio = 10\n",
        "Audio(audios_path[idx_audio])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6J0EEilRGDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_audio = 100\n",
        "Audio(audios_path[idx_audio])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s365Q_QIRShr",
        "colab_type": "text"
      },
      "source": [
        "Ensuite, vous pouvez choisir une classe à analyser:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr68eJCvRR6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Audio\n",
        "import glob\n",
        "\n",
        "class_to_explore = \"\" ## A compléter. choisissez une des classes 'bed', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', ....\n",
        "audios_path = glob.glob(dataset_path + class_to_explore + \"/*\")\n",
        "idx_audio = ## A compléter\n",
        "Audio(audios_path[idx_audio])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZB2mvx6Qj8B",
        "colab_type": "text"
      },
      "source": [
        "Selon la physique, le son est une vibration itinérante, c'est-à-dire une onde qui se déplace dans un milieu tel que l'air. L'onde sonore transfère de l'énergie de particule en particule jusqu'à ce qu'elle soit finalement \"reçue\" par nos oreilles et perçue par notre cerveau. Les deux attributs de base du son sont l'amplitude (ce que nous appelons aussi le volume sonore) et la fréquence (une mesure des vibrations de l'onde par unité de temps).\n",
        "\n",
        "Tout comme les images et les vidéos, le son est un signal analogique qui doit être transformé en un signal numérique, afin d'être stocké dans des ordinateurs et analysé par des logiciels.\n",
        "\n",
        "L'échantillonnage est utilisé pour convertir le signal continu variable dans le temps en une séquence discrète de nombres réels. Les fréquences d'échantillonnage typiques sont 8KHz, 16KHz et 44,1KHz. 1Hz signifie un échantillon par seconde, donc évidemment des fréquences d'échantillonnage plus élevées signifient plus d'échantillons par seconde et donc une meilleure qualité de signal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuqsu4T8RXML",
        "colab_type": "text"
      },
      "source": [
        "Désormais, nous utiliserons la bibliothèque *scipy* pour lire les fichiers audio.\n",
        "\n",
        "Lorsque nous lisons le signal audio avec scipy, il rend la fréquence d'échantillonnage et le signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlxSsdZIRz5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.io import wavfile\n",
        "\n",
        "audio_to_analyze = dataset_path + \"zero/004ae714_nohash_1.wav\"\n",
        "freq, signal = wavfile.read(filename=audio_to_analyze)\n",
        "print(\"Frequence d'echantillonnage: \", freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45S7ybOiS0dY",
        "colab_type": "text"
      },
      "source": [
        "Cela signifie que ce signal audio a 16000 valeurs par seconde.\n",
        "\n",
        "Comme notre ensemble de données est composé d'échantillons de 1 seconde, tous les échantillons contiennent 16000 valeurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2PaDwVyS4df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(signal.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R255wl7eWBZQ",
        "colab_type": "text"
      },
      "source": [
        "Le signal produit par scipy est juste un tableau avec toutes les valeurs échantillonnées du signal analogique.\n",
        "\n",
        "Ensuite, nous pouvons simplement le tracer dans un graphique, où l'axe des x est le temps et l'axe des y sont les valeurs du tableau, qui dans notre cas est l'amplitude du signal.\n",
        "\n",
        "Dans l'exemple suivant, vous pouvez voir clairement dans le graphique les deux syllabus du mot \"zero\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkfvjDTuUCvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(signal)\n",
        "plt.title(\"waveform\")\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n",
        "Audio(audio_to_analyze)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UgLe0soW5Gb",
        "colab_type": "text"
      },
      "source": [
        "Vous pouvez maintenant essayer avec différents échantillons du dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzcyD4usW9E4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_to_analyze = dataset_path + \"\" ## A completer.\n",
        "freq, signal = wavfile.read(filename=audio_to_analyze)\n",
        "print(\"Frequence d'echantillonnage: \", freq)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(signal)\n",
        "plt.title(\"waveform\")\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n",
        "Audio(audio_to_analyze)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPTVfInjYvV1",
        "colab_type": "text"
      },
      "source": [
        "Si vous regardez les échantillons des différentes classes, vous pouvez voir que l'amplitude varie beaucoup. L'amplitude maximale de certains audios est très faible et pour d'autres très élevée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nZmG4nbZLyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq1, sample1 = wavfile.read( dataset_path + \"zero/004ae714_nohash_1.wav\")\n",
        "freq2, sample2 = wavfile.read( dataset_path + \"up/004ae714_nohash_0.wav\")\n",
        "freq3, sample3 = wavfile.read( dataset_path + \"yes/004ae714_nohash_0.wav\")\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
        "ax1.plot(sample1)\n",
        "ax2.plot(sample2)\n",
        "ax3.plot(sample3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3bAu9r7arGw",
        "colab_type": "text"
      },
      "source": [
        "C'est un véritable problème lorsque nous travaillons avec des algorithmes de Machine Learning. \n",
        "\n",
        "C'est pourquoi, généralement en phase de prétraitement, nous normalisons les données.\n",
        "\n",
        "Le but de la normalisation est d'avoir toutes les valeurs dans la même échelle.\n",
        "\n",
        "Pour notre dataset, nous normaliserons les valeurs entre -1 et 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57xIzmO3bn58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize(audio_signal):\n",
        "  audio_signal = np.array(audio_signal) ##Audio signal as array, in case it's not\n",
        "  max_value = max(np.absolute(audio_signal)) ## Get the maximum positive value\n",
        "  norm_signal = audio_signal / max_value\n",
        "  return norm_signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdpQrWQxcMMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq1, sample1 = wavfile.read( dataset_path + \"zero/004ae714_nohash_1.wav\")\n",
        "freq2, sample2 = wavfile.read( dataset_path + \"up/004ae714_nohash_0.wav\")\n",
        "freq3, sample3 = wavfile.read( dataset_path + \"yes/004ae714_nohash_0.wav\")\n",
        "\n",
        "norm_sample1 = normalize(sample1)\n",
        "norm_sample2 = normalize(sample2)\n",
        "norm_sample3 = normalize(sample3)\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
        "ax1.plot(norm_sample1)\n",
        "ax2.plot(norm_sample2)\n",
        "ax3.plot(norm_sample3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sd7LViEcrUw",
        "colab_type": "text"
      },
      "source": [
        "Vous pouvez maintenant essayer avec différents échantillons du dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWvULXsScvRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq1, sample1 = wavfile.read( dataset_path + \"\")## A completer.\n",
        "freq2, sample2 = wavfile.read( dataset_path + \"\")## A completer.\n",
        "freq3, sample3 = wavfile.read( dataset_path + \"\")## A completer.\n",
        "\n",
        "norm_sample1 = normalize(sample1)\n",
        "norm_sample2 = normalize(sample2)\n",
        "norm_sample3 = normalize(sample3)\n",
        "\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
        "fig.suptitle(\"Signal\")\n",
        "ax1.plot(sample1)\n",
        "ax2.plot(sample2)\n",
        "ax3.plot(sample3)\n",
        "plt.show()\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
        "fig.suptitle(\"Normalized Signal\")\n",
        "ax1.plot(norm_sample1)\n",
        "ax2.plot(norm_sample2)\n",
        "ax3.plot(norm_sample3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfVdlu25djXW",
        "colab_type": "text"
      },
      "source": [
        "Si vous regardez de plus près l'ensemble des données, vous verrez que certains échantillons sont inférieurs à une seconde."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEUcOJMBd5KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signal_path = dataset_path + \"zero/f59d0771_nohash_1.wav\"\n",
        "freq, signal = wavfile.read(signal_path)\n",
        "print(signal.shape)\n",
        "\n",
        "print(\"Signal size: \", len(signal)/freq, \"seconds\")\n",
        "Audio(signal_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFvkHbT_ejOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signal_path = dataset_path + \"sheila/fbe51750_nohash_1.wav\"\n",
        "freq, signal = wavfile.read(signal_path)\n",
        "print(signal.shape)\n",
        "\n",
        "print(\"Signal size: \", len(signal)/freq, \"seconds\")\n",
        "Audio(signal_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG0poNpZfIq5",
        "colab_type": "text"
      },
      "source": [
        "Dans Machine Learning, il existe une technique très courante pour résoudre ce problème, appelée \"zero-padding\". L'idée est d'ajouter quelques 0 avant et après les signaux qui sont trop courts. Ainsi, les signaux auront la même longueur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L875_G1KfrOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "def add_padding(audio_signal, desired_len):\n",
        "  \n",
        "  length_signal = len(audio_signal)\n",
        "  if length_signal < desired_len:\n",
        "    zeros = np.zeros(desired_len)\n",
        "    start_signal = random.randint(0, desired_len - length_signal) ## Bonne Question: Pourquoi aléatoire?\n",
        "    zeros[start_signal: start_signal + length_signal] = audio_signal\n",
        "    return zeros\n",
        "    \n",
        "  return audio_signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq4yiC14hQcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signal_path = dataset_path + \"zero/f59d0771_nohash_1.wav\"\n",
        "freq, signal = wavfile.read(signal_path)\n",
        "\n",
        "print(\"Signal size before padding: \", len(signal)/freq, \"seconds\")\n",
        "\n",
        "pad_signal = add_padding(signal, freq)\n",
        "print(\"Signal size after padding: \", len(pad_signal)/freq, \"seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSthf3iaiW-C",
        "colab_type": "text"
      },
      "source": [
        "Nous pouvons également vérifier le tracé du signal, pour voir à quoi il ressemble avec le padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKp35rB1icFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(signal)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(pad_signal)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COJTJqVci44e",
        "colab_type": "text"
      },
      "source": [
        "Vous pouvez maintenant essayer avec différents échantillons du dataset.\n",
        "\n",
        "Commencez par rechercher un échantillon de moins d'une minute et utilisez la fonction de add_padding pour ajouter le padding au signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXc47FESjMLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signal_path = dataset_path + \"\" ## A completer avec un wav < 1s\n",
        "freq, signal = wavfile.read(signal_path)\n",
        "\n",
        "print(\"Signal size before padding: \", len(signal)/freq, \"seconds\")\n",
        "\n",
        "pad_signal = add_padding(signal, freq)\n",
        "print(\"Signal size after padding: \", len(pad_signal)/freq, \"seconds\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(signal) ## A completer.\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(pad_signal) ## A completer.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Tz0EqaWjsLO",
        "colab_type": "text"
      },
      "source": [
        "# Speech Recognition (Reconnaissance de la parole)\n",
        "\n",
        "Dans les prochains TD, nous travaillerons sur la tâche de reconnaissance vocale, nous essaierons d'identifier quel mot la personne dit. Pour faciliter la tâche, nous ne travaillerons qu'avec deux classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRZD77GikVgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chosen_classes = [\"sheila\", \"nine\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw9lolgzlFsm",
        "colab_type": "text"
      },
      "source": [
        "Généralement, dans Machine Learning, *X* représente les caractéristiques d'entrée et *y* représente la classe.\n",
        "\n",
        "Rassemblons tous les chemins audio de notre dataset de deux mots :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrQZO9SMlLTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "for class_name in chosen_classes:\n",
        "  class_path = dataset_path + class_name\n",
        "  for audio_path in glob.glob(class_path + \"/*.wav\"):\n",
        "    X.append(audio_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u5SSZnmlnvG",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, créons notre y contenant la classe de chacun de nos fichiers audio :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1iCKQtGlkuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "for audio_path in X:\n",
        "  y.append(audio_path.split('/')[-2])\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4sTeIdqlwEV",
        "colab_type": "text"
      },
      "source": [
        "Voyons un peu la taille de notre ensemble de données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i95pOemHlxtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('data array length:',len(X))\n",
        "print('class array length:',len(y))\n",
        "\n",
        "print('X:',X)\n",
        "print('y:',y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqkBCDVemCvG",
        "colab_type": "text"
      },
      "source": [
        "Un commentaire important à souligner dans l'apprentissage automatique est que les classes sont généralement représentées par des valeurs numériques au lieu de valeurs textuelles. Ainsi, au lieu d'utiliser les mots, nous utiliserons 0 pour le premier mot et 1 pour le second."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsIn-W_BmEz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Écrivez le code pour créer un nouveau vecteur y, où il a 0 au lieu du premier mot et 1 au lieu du deuxième mot\n",
        "y_num = []\n",
        "for y_string in y:\n",
        "  if chosen_classes[0] in y_string:\n",
        "    y.append(0)\n",
        "    ...... ## To complete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3HjE4nwmUb5",
        "colab_type": "text"
      },
      "source": [
        "Scikit-learn est une bibliothèque de Machine Learning en logiciel libre pour Python. Elle fournit de nombreuses méthodes et algorithmes utiles.\n",
        "\n",
        "Nous allons commencer à utiliser le paquet de prétraitement pour remplacer le code que vous avez fait dans la cellule précédente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuU1oW-ImbGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "changer les classes des chaînes de caractères en chiffres\n",
        "'''\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y)\n",
        "y = le.transform(y)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFN8LyaqmsWA",
        "colab_type": "text"
      },
      "source": [
        "Comme nous l'avons vu dans les diapositives de la classe, l'ensemble de données est généralement divisé en trois parties différentes : Train, Test et Validation.\n",
        "\n",
        "Faisons le code pour diviser l'ensemble de données : 80% pour le train, 10% pour le test et 10% pour la validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPqO4o7rmxMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Code to split the dataset\n",
        "X_train = \n",
        "X_test = \n",
        "X_val =\n",
        "\n",
        "y_train =\n",
        "y_test =\n",
        "y_val =\n",
        "\n",
        "print('training samples:',len(X_train))\n",
        "print('testing samples:',len(X_test))\n",
        "print('validation samples:',len(X_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEoKBO_6m2EZ",
        "colab_type": "text"
      },
      "source": [
        "Scikit-learn fournit également un paquet permettant de diviser l'ensemble de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCpT5pUlm4xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , test_size=0.2, stratify=y)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
        "\n",
        "print('training samples:',len(X_train))\n",
        "print('testing samples:',len(X_test))\n",
        "print('validation samples:',len(X_val))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}